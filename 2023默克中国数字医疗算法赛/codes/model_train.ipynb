{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42513fd",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e495a8e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:01:59.180846Z",
     "start_time": "2023-04-11T10:59:48.070361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HXH\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from gensim.models import Word2Vec\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier as cat\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss, mean_squared_log_error, precision_recall_curve, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b0b966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:01:59.260374Z",
     "start_time": "2023-04-11T11:01:59.181834Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE # 导入tsne包\n",
    "from sklearn.decomposition import PCA, KernelPCA # PCA\n",
    "from sklearn.manifold import Isomap # Isomap\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb0888e",
   "metadata": {},
   "source": [
    "## 数据读取和基本处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c961cc",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bfa5991",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:01:59.555839Z",
     "start_time": "2023-04-11T11:01:59.261485Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取疾病特征数据集（训练集）\n",
    "disease_feature1 = pd.read_csv(\"./data/train/disease_feature1.csv\")\n",
    "disease_feature2 = pd.read_csv(\"./data/train/disease_feature2.csv\")\n",
    "disease_feature3 = pd.read_csv(\"./data/train/disease_feature3.csv\")\n",
    "\n",
    "# 读取 train_food 和 train_answer（训练集）\n",
    "train_food = pd.read_csv(\"./data/train/train_food.csv\")\n",
    "train_answer = pd.read_csv(\"./data/train/train_answer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b629dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:01:59.571066Z",
     "start_time": "2023-04-11T11:01:59.556853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>is_related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food_0</td>\n",
       "      <td>disease_998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food_0</td>\n",
       "      <td>disease_861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>food_0</td>\n",
       "      <td>disease_559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food_0</td>\n",
       "      <td>disease_841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food_0</td>\n",
       "      <td>disease_81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  food_id   disease_id  is_related\n",
       "0  food_0  disease_998           0\n",
       "1  food_0  disease_861           0\n",
       "2  food_0  disease_559           0\n",
       "3  food_0  disease_841           0\n",
       "4  food_0   disease_81           0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train_answer\n",
    "data = data.rename(columns={\"related\":\"is_related\"})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e4afa61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:01:59.587097Z",
     "start_time": "2023-04-11T11:01:59.571066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_id</th>\n",
       "      <th>N_0</th>\n",
       "      <th>N_1</th>\n",
       "      <th>N_2</th>\n",
       "      <th>N_3</th>\n",
       "      <th>N_4</th>\n",
       "      <th>N_5</th>\n",
       "      <th>N_6</th>\n",
       "      <th>N_7</th>\n",
       "      <th>N_8</th>\n",
       "      <th>...</th>\n",
       "      <th>N_202</th>\n",
       "      <th>N_203</th>\n",
       "      <th>N_204</th>\n",
       "      <th>N_205</th>\n",
       "      <th>N_206</th>\n",
       "      <th>N_207</th>\n",
       "      <th>N_208</th>\n",
       "      <th>N_209</th>\n",
       "      <th>N_210</th>\n",
       "      <th>N_211</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food_0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.5</td>\n",
       "      <td>92.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>food_4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>15.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food_5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3</td>\n",
       "      <td>86.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.6</td>\n",
       "      <td>93.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  food_id  N_0  N_1  N_2    N_3  N_4    N_5   N_6    N_7  N_8  ...  N_202  \\\n",
       "0  food_0  NaN  NaN  NaN    NaN  0.0    NaN   NaN    NaN  NaN  ...    NaN   \n",
       "1  food_1  NaN  NaN  NaN    NaN  0.0    NaN   NaN    NaN  NaN  ...    NaN   \n",
       "2  food_4  NaN  NaN  NaN    NaN  0.0    NaN   NaN    NaN  NaN  ...    NaN   \n",
       "3  food_5  NaN  NaN  NaN  0.068  0.0  0.045  0.75  0.314  NaN  ...    NaN   \n",
       "4  food_6  NaN  NaN  NaN  0.115  0.0  0.091  0.58  0.508  NaN  ...    NaN   \n",
       "\n",
       "   N_203  N_204  N_205  N_206  N_207  N_208  N_209  N_210  N_211  \n",
       "0    NaN   0.02    0.0    NaN    NaN   30.5  92.82    NaN   0.92  \n",
       "1    NaN  23.90    0.0    NaN    NaN    0.0   2.41    NaN   3.31  \n",
       "2    NaN   0.12    0.0    NaN    NaN    3.5  15.46    NaN   0.36  \n",
       "3    NaN   0.89    0.0    NaN    NaN    3.3  86.35    NaN   0.20  \n",
       "4    NaN   1.13    0.0    0.0    NaN   41.6  93.22    NaN   0.54  \n",
       "\n",
       "[5 rows x 213 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food = train_food\n",
    "food.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbbb975",
   "metadata": {},
   "source": [
    "### 对food_id和disease_id进行编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3352a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:01:59.680416Z",
     "start_time": "2023-04-11T11:01:59.588096Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"food\"] = data[\"food_id\"].apply(lambda x: int(x.split(\"_\")[-1]))\n",
    "data[\"disease\"] = data[\"disease_id\"].apply(lambda x: int(x.split(\"_\")[-1]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026f967a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:00.332585Z",
     "start_time": "2023-04-11T11:01:59.681349Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 19.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# 目标编码\n",
    "cat_list = ['disease']\n",
    "\n",
    "def stat(df, df_merge, group_by, agg):\n",
    "    group = df.groupby(group_by).agg(agg)\n",
    "\n",
    "    columns = []\n",
    "    for on, methods in agg.items():\n",
    "        for method in methods:\n",
    "            columns.append('{}_{}_{}'.format('_'.join(group_by), on, method))\n",
    "    group.columns = columns\n",
    "    group.reset_index(inplace=True)\n",
    "    df_merge = df_merge.merge(group, on=group_by, how='left')\n",
    "\n",
    "    del (group)\n",
    "    gc.collect()\n",
    "    return df_merge\n",
    "\n",
    "def statis_feat(df_know, df_unknow, cat_list):  # 统计特征\n",
    "    for f in tqdm(cat_list):\n",
    "        df_unknow = stat(df_know, df_unknow, [f], {'is_related': ['mean']})\n",
    "\n",
    "    return df_unknow\n",
    "\n",
    "df_train = data[~data['is_related'].isnull()]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = data[data['is_related'].isnull()]\n",
    "\n",
    "df_stas_feat = None\n",
    "kf = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "for train_index, val_index in kf.split(df_train, df_train['is_related']):\n",
    "    df_fold_train = df_train.iloc[train_index]\n",
    "    df_fold_val = df_train.iloc[val_index]\n",
    "\n",
    "    df_fold_val = statis_feat(df_fold_train, df_fold_val, cat_list)\n",
    "    df_stas_feat = pd.concat([df_stas_feat, df_fold_val], axis=0)\n",
    "\n",
    "    del (df_fold_train)\n",
    "    del (df_fold_val)\n",
    "    gc.collect()\n",
    "\n",
    "df_test = statis_feat(df_train, df_test, cat_list)\n",
    "data = pd.concat([df_stas_feat, df_test], axis=0)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "del (df_stas_feat)\n",
    "del (df_train)\n",
    "del (df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73085911",
   "metadata": {},
   "source": [
    "## 疾病特征处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72713558",
   "metadata": {},
   "source": [
    "### 缺失值填0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7204f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:00.348362Z",
     "start_time": "2023-04-11T11:02:00.332585Z"
    }
   },
   "outputs": [],
   "source": [
    "disease_feature1 = disease_feature1.fillna(0)\n",
    "disease_feature2 = disease_feature2.fillna(0)\n",
    "disease_feature3 = disease_feature3.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be2f7a",
   "metadata": {},
   "source": [
    "### 降维前归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba22cb97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:00.410814Z",
     "start_time": "2023-04-11T11:02:00.348966Z"
    }
   },
   "outputs": [],
   "source": [
    "def standard_disease(df):\n",
    "    \"\"\"\n",
    "    降维前归一化\n",
    "    \"\"\"\n",
    "    std = MinMaxScaler()\n",
    "    disease_id_array = df[\"disease_id\"]\n",
    "    cols = [f for f in df.columns if f not in [\"disease_id\"]]\n",
    "    df_std = std.fit_transform(df[cols])\n",
    "    df_temp = pd.DataFrame(data = df_std[0:, 0:], columns = cols)\n",
    "    df_disease_id = pd.DataFrame(data=disease_id_array, columns = [\"disease_id\"])\n",
    "    df = pd.concat([df_disease_id, df_temp], axis=1)\n",
    "    return df\n",
    "disease_feature1 = standard_disease(disease_feature1)\n",
    "disease_feature2 = standard_disease(disease_feature2)\n",
    "disease_feature3 = standard_disease(disease_feature3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22572ca2",
   "metadata": {},
   "source": [
    "  ### PCA降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3ec60c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:00.739006Z",
     "start_time": "2023-04-11T11:02:00.412850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 129)\n",
      "(301, 145)\n",
      "(392, 257)\n"
     ]
    }
   ],
   "source": [
    "## PCA 对疾病特征数据集进行降维处理 \n",
    "def pca(df, n):\n",
    "    disease_id_array = df[\"disease_id\"]\n",
    "    df_pca = PCA(n_components=n).fit_transform(df.iloc[:, 1:])\n",
    "    df_temp = pd.DataFrame(data=df_pca[0:, 0:], columns = [ \"F_\" + str(item) for item in range(df_pca.shape[1])])\n",
    "    df_disease_id = pd.DataFrame(data=disease_id_array, columns = [\"disease_id\"])\n",
    "    df_disease = pd.concat([df_disease_id, df_temp], axis=1)\n",
    "    print(df_disease.shape)\n",
    "    return df_disease\n",
    "\n",
    "# pca\n",
    "df_disease1 = pca(disease_feature1, 128)\n",
    "df_disease2 = pca(disease_feature2, 144)\n",
    "df_disease3 = pca(disease_feature3, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f621b8",
   "metadata": {},
   "source": [
    "## 数据合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f5f6c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:01.954602Z",
     "start_time": "2023-04-11T11:02:00.739992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_id</th>\n",
       "      <th>disease_id</th>\n",
       "      <th>is_related</th>\n",
       "      <th>food</th>\n",
       "      <th>disease</th>\n",
       "      <th>disease_is_related_mean</th>\n",
       "      <th>N_0</th>\n",
       "      <th>N_1</th>\n",
       "      <th>N_2</th>\n",
       "      <th>N_3</th>\n",
       "      <th>...</th>\n",
       "      <th>F_246</th>\n",
       "      <th>F_247</th>\n",
       "      <th>F_248</th>\n",
       "      <th>F_249</th>\n",
       "      <th>F_250</th>\n",
       "      <th>F_251</th>\n",
       "      <th>F_252</th>\n",
       "      <th>F_253</th>\n",
       "      <th>F_254</th>\n",
       "      <th>F_255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>food_0</td>\n",
       "      <td>disease_861</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>861</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013086</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>-0.038002</td>\n",
       "      <td>-0.022234</td>\n",
       "      <td>-0.030239</td>\n",
       "      <td>-0.047222</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>-0.071890</td>\n",
       "      <td>-0.018778</td>\n",
       "      <td>-0.045336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>food_0</td>\n",
       "      <td>disease_839</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>839</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046618</td>\n",
       "      <td>0.052718</td>\n",
       "      <td>-0.036865</td>\n",
       "      <td>-0.044638</td>\n",
       "      <td>-0.076461</td>\n",
       "      <td>-0.092308</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>-0.032527</td>\n",
       "      <td>0.083290</td>\n",
       "      <td>0.035846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>food_0</td>\n",
       "      <td>disease_50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.018382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008846</td>\n",
       "      <td>-0.010672</td>\n",
       "      <td>-0.013317</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.032617</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>-0.044105</td>\n",
       "      <td>0.017589</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>-0.009265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food_0</td>\n",
       "      <td>disease_1370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1370</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.018879</td>\n",
       "      <td>-0.005077</td>\n",
       "      <td>0.055209</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>-0.050008</td>\n",
       "      <td>-0.008424</td>\n",
       "      <td>0.015456</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.011667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food_0</td>\n",
       "      <td>disease_1015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1015</td>\n",
       "      <td>0.202749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038134</td>\n",
       "      <td>0.048754</td>\n",
       "      <td>-0.045703</td>\n",
       "      <td>-0.042401</td>\n",
       "      <td>-0.021547</td>\n",
       "      <td>-0.003382</td>\n",
       "      <td>-0.055510</td>\n",
       "      <td>0.035909</td>\n",
       "      <td>-0.019242</td>\n",
       "      <td>-0.002197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 746 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  food_id    disease_id  is_related  food  disease  disease_is_related_mean  \\\n",
       "0  food_0   disease_861           0     0      861                 0.003521   \n",
       "1  food_0   disease_839           0     0      839                 0.007299   \n",
       "2  food_0    disease_50           0     0       50                 0.018382   \n",
       "3  food_0  disease_1370           0     0     1370                 0.214286   \n",
       "4  food_0  disease_1015           0     0     1015                 0.202749   \n",
       "\n",
       "   N_0  N_1  N_2  N_3  ...     F_246     F_247     F_248     F_249     F_250  \\\n",
       "0  NaN  NaN  NaN  NaN  ... -0.013086  0.007805 -0.038002 -0.022234 -0.030239   \n",
       "1  NaN  NaN  NaN  NaN  ...  0.046618  0.052718 -0.036865 -0.044638 -0.076461   \n",
       "2  NaN  NaN  NaN  NaN  ...  0.008846 -0.010672 -0.013317  0.007108  0.032617   \n",
       "3  NaN  NaN  NaN  NaN  ...  0.002464  0.018879 -0.005077  0.055209  0.005366   \n",
       "4  NaN  NaN  NaN  NaN  ... -0.038134  0.048754 -0.045703 -0.042401 -0.021547   \n",
       "\n",
       "      F_251     F_252     F_253     F_254     F_255  \n",
       "0 -0.047222  0.020007 -0.071890 -0.018778 -0.045336  \n",
       "1 -0.092308  0.010530 -0.032527  0.083290  0.035846  \n",
       "2  0.014577 -0.044105  0.017589  0.009023 -0.009265  \n",
       "3 -0.050008 -0.008424  0.015456  0.020397  0.011667  \n",
       "4 -0.003382 -0.055510  0.035909 -0.019242 -0.002197  \n",
       "\n",
       "[5 rows x 746 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.merge(data, food, on=\"food_id\", how=\"left\")\n",
    "data = pd.merge(data, df_disease1, on=\"disease_id\", how=\"left\")\n",
    "data = pd.merge(data, df_disease2, on=\"disease_id\", how=\"left\")\n",
    "data = pd.merge(data, df_disease3, on=\"disease_id\", how=\"left\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91622223",
   "metadata": {},
   "source": [
    "## 长尾特征截尾处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f0d162d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:02.518295Z",
     "start_time": "2023-04-11T11:02:01.955592Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.17it/s]\n"
     ]
    }
   ],
   "source": [
    "cols = [\"N_14\", \"N_59\", \"N_60\", \"N_61\", \"N_85\", \"N_165\", \"N_198\", \"N_193\", \"N_204\", \"N_211\"]\n",
    "def log1p(df, col):\n",
    "    df[col] = np.log1p(df[col])\n",
    "for c in tqdm(cols):\n",
    "    log1p(data, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718c098",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daacca6e",
   "metadata": {},
   "source": [
    "### 重要特征交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6790fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:02.658995Z",
     "start_time": "2023-04-11T11:02:02.519292Z"
    }
   },
   "outputs": [],
   "source": [
    "topn = [\"N_33\", \"N_42\", \"N_43\", \"N_74\", \"N_106\", \"N_111\", \"N_209\", \"disease\", \"food\"]\n",
    "for i in range(len(topn)):\n",
    "    for j in range(i + 1, len(topn)):\n",
    "        data[f\"{topn[i]}+{topn[j]}\"] = data[topn[i]] + data[topn[j]]\n",
    "        data[f\"{topn[i]}-{topn[j]}\"] = data[topn[i]] - data[topn[j]]\n",
    "        data[f\"{topn[i]}*{topn[j]}\"] = data[topn[i]] * data[topn[j]]\n",
    "        data[f\"{topn[i]}/{topn[j]}\"] = data[topn[i]] / (data[topn[j]] + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e4c3661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:02.691012Z",
     "start_time": "2023-04-11T11:02:02.659912Z"
    }
   },
   "outputs": [],
   "source": [
    "## 特征交叉 重要食物特征与疾病特征\n",
    "topn = [\"N_33\", \"F_82_x\", \"F_39_x\"]\n",
    "for i in range(len(topn)):\n",
    "    for j in range(i + 1, len(topn)):\n",
    "        data[f\"{topn[i]}+{topn[j]}\"] = data[topn[i]] + data[topn[j]]\n",
    "        data[f\"{topn[i]}-{topn[j]}\"] = data[topn[i]] - data[topn[j]]\n",
    "        data[f\"{topn[i]}*{topn[j]}\"] = data[topn[i]] * data[topn[j]]\n",
    "        data[f\"{topn[i]}/{topn[j]}\"] = data[topn[i]] / (data[topn[j]] + 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6054702",
   "metadata": {},
   "source": [
    "### 重要特征分箱处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9984f3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:07.098139Z",
     "start_time": "2023-04-11T11:02:02.692020Z"
    }
   },
   "outputs": [],
   "source": [
    "## 重要特征分箱处理\n",
    "### N_33\n",
    "def get_N_33_seg(x):\n",
    "    if x >= 0 and x <= 0.125:\n",
    "        return 0\n",
    "    elif x > 0.125 and x <= 1.25:\n",
    "        return 1\n",
    "    elif x > 1.25 and x <= np.max(data[\"N_33\"]):\n",
    "        return 2\n",
    "\n",
    "data[\"N33_seg\"] = data[\"N_33\"].apply(lambda x: get_N_33_seg(x))\n",
    "\n",
    "### N_42\n",
    "def get_N_42_seg(x):\n",
    "    if x >= 0 and x <= 500:\n",
    "        return 0\n",
    "    elif x > 500 and x <= 1000:\n",
    "        return 1\n",
    "    elif x > 1000 and x <= np.max(data[\"N_42\"]):\n",
    "        return 2\n",
    "\n",
    "data[\"N42_seg\"] = data[\"N_42\"].apply(lambda x: get_N_42_seg(x))\n",
    "\n",
    "# N_43\n",
    "def get_N_43_seg(x):\n",
    "    if x >=0 and x <= 20:\n",
    "        return 0\n",
    "    elif x > 20 and x <= 38:\n",
    "        return 1\n",
    "    elif x > 38 and x <= 50:\n",
    "        return 2\n",
    "    elif x > 50 and x <= np.max(data[\"N_43\"]):\n",
    "        return 3\n",
    "data[\"N43_seg\"] = data[\"N_43\"].apply(lambda x: get_N_43_seg(x))\n",
    "\n",
    "### N_74\n",
    "def get_N_74_seg(x):\n",
    "    if x >=0 and x <= 2:\n",
    "        return 0\n",
    "    elif x > 2 and x <= 10:\n",
    "        return 1\n",
    "    elif x > 10 and x <= np.max(data[\"N_74\"]):\n",
    "        return 2\n",
    "\n",
    "data[\"N74_seg\"] = data[\"N_74\"].apply(lambda x: get_N_74_seg(x))\n",
    "\n",
    "### N_106\n",
    "def get_N_106_seg(x):\n",
    "    if x >= 0 and x <= 50:\n",
    "        return 0\n",
    "    elif x > 50 and x <= 150:\n",
    "        return 1\n",
    "    elif x > 150 and x <= 300:\n",
    "        return 2\n",
    "    elif x > 300 and x < np.max(data[\"N_106\"]):\n",
    "        return 3\n",
    "\n",
    "data[\"N106_seg\"] = data[\"N_106\"].apply(lambda x: get_N_106_seg(x))\n",
    "\n",
    "### N_111\n",
    "def get_N_111_seg(x):\n",
    "    if x >= 0 and x <= 500:\n",
    "        return 0\n",
    "    elif x > 500 and x <= 2000:\n",
    "        return 1\n",
    "    elif x > 2000 and x <= np.max(data[\"N_111\"]):\n",
    "        return 2\n",
    "\n",
    "data[\"N111_seg\"] = data[\"N_111\"].apply(lambda x: get_N_111_seg(x))\n",
    "\n",
    "### food\n",
    "data['food_qcut'] = pd.qcut(data['food'], 10, labels=False, duplicates='drop')\n",
    "\n",
    "### disease\n",
    "data['disease_qcut'] = pd.qcut(data['disease'], 14, labels=False, duplicates='drop')\n",
    "\n",
    "### N_209\n",
    "data['N_209_qcut'] = pd.qcut(data['N_209'], 10, labels=False, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3c280c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:07.317170Z",
     "start_time": "2023-04-11T11:02:07.099140Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 20.16it/s]\n"
     ]
    }
   ],
   "source": [
    "def static_feature(df, features, groups):\n",
    "    for method in tqdm(['mean', 'std', 'max', 'min']):\n",
    "        for feature in features:\n",
    "            for group in groups:\n",
    "                df[f'{group}_{feature}_{method}'] = df.groupby(group)[feature].transform(method)\n",
    "    return df\n",
    "\n",
    "dense_feats = [\"N_33*disease\", \n",
    "\"N_42+disease\", \"N_42-disease\", \"N_42*disease\", \n",
    "\"N_43+disease\", \"N_43*disease\", \n",
    "\"N_74*disease\", \n",
    "\"N_111+disease\", \"N_111-disease\", \"N_111*disease\",\n",
    "\"N_33+F_82_x\", \"N_33+F_39_x\",\n",
    "]\n",
    "cat_feats = ['food']\n",
    "data = static_feature(data, dense_feats, cat_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002af25",
   "metadata": {},
   "source": [
    "## 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc29f0e5",
   "metadata": {},
   "source": [
    "### 根据特征重要性筛选特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d38f7180",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:07.691034Z",
     "start_time": "2023-04-11T11:02:07.318169Z"
    }
   },
   "outputs": [],
   "source": [
    "feat_imp = pd.read_csv(\"./features_importance.csv\")\n",
    "feat_no_imp = feat_imp[(feat_imp[\"imp\"] < 100)].reset_index(drop=True)\n",
    "no_imp_cols = feat_no_imp.feats.tolist()\n",
    "data = data.drop(no_imp_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be14d71d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:07.706311Z",
     "start_time": "2023-04-11T11:02:07.692033Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_cols = [\"disease_id\", \"food_id\", \"is_related\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d72953",
   "metadata": {},
   "source": [
    "### 去除只有单一取值的特征（剔除低方差特征）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cb6998e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:09.010432Z",
     "start_time": "2023-04-11T11:02:07.706843Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    if data[col].nunique() < 2:\n",
    "        drop_cols.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f611f025",
   "metadata": {},
   "source": [
    "### 删除缺失率过高的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06aec28a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:35.021539Z",
     "start_time": "2023-04-11T11:02:09.011336Z"
    }
   },
   "outputs": [],
   "source": [
    "def dropNaN(df, p, col):\n",
    "    na_sum = df[col].isna().sum()\n",
    "    percent_value = na_sum / len(df[col])\n",
    "    if percent_value >= p:\n",
    "        df = df.drop([col], axis=1)\n",
    "    return df\n",
    "for c in data.columns:\n",
    "    data = dropNaN(data, 0.95, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e814c0d",
   "metadata": {},
   "source": [
    "## 保存特征以及分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f529ad44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:35.036916Z",
     "start_time": "2023-04-11T11:02:35.023036Z"
    }
   },
   "outputs": [],
   "source": [
    "features_name = [f for f in data.columns if f not in drop_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53babf51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:35.952215Z",
     "start_time": "2023-04-11T11:02:35.038448Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data[features_name].reset_index(drop=True)\n",
    "label = data[\"is_related\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b866ce",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f84731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T11:02:35.983765Z",
     "start_time": "2023-04-11T11:02:35.983765Z"
    }
   },
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name):\n",
    "    folds = 10 # 10折比5折好\n",
    "    seed = 2023\n",
    "#     kf = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    \n",
    "    oof = np.zeros(train_x.shape[0]) # 初始化一个大小为n（n=训练集行数），值全为0的数组 用于存放每折验证集的预测概率\n",
    "    predict = np.zeros(test_x.shape[0]) # 初始化一个大小为n（n=测试集行数），值全为0的数组 用于存放预测概率\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y) # 该折训练集矩阵\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y) # 该折验证集矩阵\n",
    "\n",
    "            params = {\n",
    "                'learning_rate': 0.01,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc',\n",
    "                'num_leaves': 63,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 5,\n",
    "                'seed': 2022,\n",
    "                'bagging_seed': 1,\n",
    "                'feature_fraction_seed': 7,\n",
    "                'min_data_in_leaf': 20,\n",
    "                'verbose': -1, \n",
    "                'n_jobs':8,\n",
    "            }\n",
    "            # 模型训练 valid_sets也可以只放valid_matrix verbose_eval表示打印信息的间隔 early_stopping_rounds表示早停，\n",
    "            # 防止过拟合，表示在验证集上,当连续n次迭代,分数没有提高后,提前终止训练\n",
    "            model = clf.train(params, train_matrix, 100000, valid_sets=[train_matrix, valid_matrix], \n",
    "                              categorical_feature=[], verbose_eval=100, early_stopping_rounds=500) \n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration) # 预测该折验证集 最优迭代次数\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration) # 该折训练下的模型来预测测试集\n",
    "            \n",
    "#             print(list(sorted(zip(cols, model.feature_importance(\"gain\")), key=lambda x: x[1], reverse=True))[:20])\n",
    "                \n",
    "        if clf_name == \"xgb\":\n",
    "            train_matrix = clf.DMatrix(trn_x , label=trn_y) # 该折该折训练集矩阵\n",
    "            valid_matrix = clf.DMatrix(val_x , label=val_y) # 该折验证集矩阵\n",
    "            test_matrix = clf.DMatrix(test_x) # 测试集矩阵\n",
    "            \n",
    "#             params = {'booster': 'gbtree',\n",
    "#                       'objective': 'binary:logistic',\n",
    "#                       'eval_metric': ['auc', 'ndcg'],\n",
    "#                       'gamma': 1,\n",
    "#                       'min_child_weight': 1.5,\n",
    "#                       'max_depth': 5,\n",
    "#                       'lambda': 10,\n",
    "#                       'subsample': 0.7,\n",
    "#                       'colsample_bytree': 0.7,\n",
    "#                       'colsample_bylevel': 0.7,\n",
    "#                       'eta': 0.05,\n",
    "#                       'seed': 2020,\n",
    "#                       'nthread': 8,\n",
    "#                       'gpu_id':0,\n",
    "#                       'tree_method':'gpu_hist'\n",
    "#                       }\n",
    "            ## optuna调参\n",
    "            params = {'booster': 'gbtree',\n",
    "                          'objective': 'binary:logistic',\n",
    "                          'eval_metric': 'auc',\n",
    "                          'gamma': 1.6102,\n",
    "                          'min_child_weight': 1.331,\n",
    "                          'max_depth': 8,\n",
    "                          'subsample': 0.6538,\n",
    "                          'colsample_bytree': 0.5433,\n",
    "                          'colsample_bylevel': 0.7,\n",
    "                          'reg_alpha':0.0118,\n",
    "                          'reg_lambda':1.79e-05,\n",
    "                          'eta': 0.0554,\n",
    "                          'seed': 2020,\n",
    "                          'nthread': 8,\n",
    "                          'gpu_id': 0,\n",
    "                          'tree_method': 'gpu_hist'\n",
    "                          }\n",
    "            \n",
    "            watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "            model = clf.train(params, train_matrix, num_boost_round=10000, evals=watchlist, verbose_eval=100, early_stopping_rounds=500)\n",
    "            pickle.dump(model, open(f\"./model/xgb_model{i}\", \"wb\"))\n",
    "            pickle.dump(model.best_ntree_limit, open(f\"./model/xgb_model_best_ntree_limit{i}\", \"wb\"))\n",
    "            \n",
    "            val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit) # 最优模型时对应树的个数\n",
    "            test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit)\n",
    "                 \n",
    "        if clf_name == \"cat\":\n",
    "            \n",
    "            model = clf(\n",
    "            n_estimators=10000,\n",
    "            random_seed=1024,\n",
    "            eval_metric='AUC',\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            early_stopping_rounds=500,\n",
    "            metric_period=500,\n",
    "            task_type='GPU'\n",
    "                    )\n",
    "\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      use_best_model=True,\n",
    "                      verbose=1)\n",
    "            \n",
    "            pickle.dump(model, open(f\"./model/cat_model{i}\", \"wb\"))\n",
    "            \n",
    "            val_pred  = model.predict_proba(val_x)[:,1]\n",
    "            test_pred = model.predict_proba(test_x)[:,1]\n",
    "        \n",
    "        oof[valid_index] = val_pred # 将每一折验证集的预测结果放入原先的初始化矩阵中（每一折会对应索引valid_index）\n",
    "        \n",
    "        predict += test_pred / folds # ？\n",
    "        \n",
    "        \n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        print(cv_scores)\n",
    "    return model, oof, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d30b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "xgb_oof = cv_model(xgb, X, label, 'xgb')\n",
    "end_time = datetime.now() \n",
    "print(end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
