{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "868866c3",
   "metadata": {},
   "source": [
    "# 导入第三方包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabaffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier as cat\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss, mean_squared_log_error, precision_recall_curve, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import argparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.manifold import TSNE # 导入tsne包\n",
    "from sklearn.decomposition import PCA, KernelPCA # PCA\n",
    "from sklearn.manifold import Isomap # Isomap\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdb81e7",
   "metadata": {},
   "source": [
    "# 数据读取与基本处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f465ed",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集数据\n",
    "acct_train = pd.read_csv('../input/赛题B_预赛数据/训练集/acct_train.csv')\n",
    "bhv_train = pd.read_csv('../input/赛题B_预赛数据/训练集/bhv_train.csv')\n",
    "cust_train = pd.read_csv('../input/赛题B_预赛数据/训练集/cust_train.csv')\n",
    "train_label = pd.read_csv('../input/赛题B_预赛数据/训练集/train_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75efd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集数据\n",
    "acct_test = pd.read_csv('../input/赛题B_预赛数据/测试集/acct_test.csv')\n",
    "bhv_test = pd.read_csv('../input/赛题B_预赛数据/测试集/bhv_test.csv')\n",
    "cust_test = pd.read_csv('../input/赛题B_预赛数据/测试集/cust_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6dd8d",
   "metadata": {},
   "source": [
    "## 数据拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da2181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data\n",
    "train_data = pd.merge(acct_train, bhv_train, on=\"id\", how=\"left\")\n",
    "train_data = pd.merge(train_data, cust_train, on=\"id\", how=\"left\")\n",
    "train_data = pd.merge(train_data, train_label, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data\n",
    "test_data = pd.merge(acct_test, bhv_test, on=\"id\", how=\"left\")\n",
    "test_data = pd.merge(test_data, cust_test, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa97073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接 train 和 test\n",
    "data = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecac4ee6",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ad455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别型特征编码处理\n",
    "cat_f = ['b2', 'b3', 'b28']\n",
    "for f in tqdm(cat_f):\n",
    "    le = LabelEncoder()\n",
    "    data[f] = le.fit_transform(data[f].fillna('nan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e48a8d",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e7ab1a",
   "metadata": {},
   "source": [
    "## 重要特征交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "topn = [\"b26\", \"b22\", \"b18\", \"b25\", \"b10\", \"b11\", \"b23\", \"b21\", \n",
    "        \"b20\", \"b13\", \"b27\", \"b24\", \"b17\", \"b14\", \"b12\", \"b15\", \n",
    "        \"b16\", \"b29\", \"b8\", \"b19\"] \n",
    "for i in range(len(topn)):\n",
    "    for j in range(i+1, len(topn)):\n",
    "        data[f\"{topn[i]}+{topn[j]}\"] = data[topn[i]] + data[topn[j]]\n",
    "        data[f\"{topn[i]}-{topn[j]}\"] = data[topn[i]] - data[topn[j]]\n",
    "        data[f\"{topn[i]}*{topn[j]}\"] = data[topn[i]] * data[topn[j]]\n",
    "        data[f\"{topn[i]}/{topn[j]}\"] = data[topn[i]] / (data[topn[j]]+1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed0f7b6",
   "metadata": {},
   "source": [
    "## 计算额度使用率、账单金额、月消费金额的变异系数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c0966",
   "metadata": {},
   "source": [
    "### 近3个月内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9b4378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算变异系数以了解用户信用卡额度使用率、账单金额、月消费金额的稳定性\n",
    "\n",
    "# 变异系数计算方式为 标准差 / 均值\n",
    "# 3个月内变异系数\n",
    "# 计算近三个月额度使用率的变异系数\n",
    "data[\"ed_mid\"] = data[\"b13\"]*3 - data[\"b14\"]- data[\"b15\"] # 如此就知道近三个月中每个月的额度使用率\n",
    "data['ed_byxs'] = data[['b14', 'ed_mid', 'b15']].apply(lambda x: np.std(x) / np.mean(x), axis=1)\n",
    "# 计算近三个月账单的变异系数\n",
    "data[\"zd_mid\"] = data[\"b19\"]*3 - data[\"b20\"]- data[\"b21\"] \n",
    "data['zd_byxs'] = data[['b20', 'zd_mid', 'b21']].apply(lambda x: np.std(x) / (np.mean(x)), axis=1)\n",
    "# 计算近三个月月消费金额的变异系数\n",
    "data[\"xf_mid\"] = data[\"b25\"]*3 - data[\"b26\"]- data[\"b27\"] \n",
    "data['xf_byxs'] = data[['b26', 'xf_mid', 'b27']].apply(lambda x: np.std(x) / (np.mean(x)), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9431d",
   "metadata": {},
   "source": [
    "### 3个月间（近半年的前3个月与近3个月）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ee73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3个月间变异系数\n",
    "# ed\n",
    "data[\"half_year_ed_sum\"] = data[\"b10\"]*6 # 近6个月\n",
    "data[\"3_month_ed_sum\"] = data[\"b13\"]*3 # 近3个月\n",
    "data[\"half_year-3_month_ed\"] = data[\"half_year_ed_sum\"]-data[\"3_month_ed_sum\"]\n",
    "data['ed_byxs_3_month'] = data[['half_year-3_month_ed', '3_month_ed_sum']].apply(lambda x: np.std(x) / np.mean(x), axis=1)\n",
    "\n",
    "# zd\n",
    "data[\"half_year_zd_sum\"] = data[\"b16\"]*6 # 近6个月\n",
    "data[\"3_month_zd_sum\"] = data[\"b19\"]*3 # 近3个月\n",
    "data[\"half_year-3_month_zd\"] = data[\"half_year_zd_sum\"]-data[\"3_month_zd_sum\"]\n",
    "data['zd_byxs_3_month'] = data[['half_year-3_month_zd', '3_month_zd_sum']].apply(lambda x: np.std(x) / np.mean(x), axis=1)\n",
    "\n",
    "# xf\n",
    "data[\"half_year_xf_sum\"] = data[\"b22\"]*6 # 近6个月\n",
    "data[\"3_month_xf_sum\"] = data[\"b25\"]*3 # 近3个月\n",
    "data[\"half_year-3_month_xf\"] = data[\"half_year_xf_sum\"]-data[\"3_month_xf_sum\"]\n",
    "data['xf_byxs_3_month'] = data[['half_year-3_month_xf', '3_month_xf_sum']].apply(lambda x: np.std(x) / np.mean(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da5008",
   "metadata": {},
   "source": [
    "## 计算额度使用率、账单金额、月消费金额的偏度与峰度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 了解用户的信用卡额度使用率、账单金额、月消费金额是否具有偏态和峰态\n",
    "\n",
    "# 3个月内偏度和峰度\n",
    "from scipy.stats import kurtosis, skew\n",
    "data['ed_sk'] = data[['b14', 'ed_mid', 'b15']].apply(lambda x: skew(x), axis=1) # 注意加上 axis=1\n",
    "data['ed_ku'] = data[['b14', 'ed_mid', 'b15']].apply(lambda x: kurtosis(x), axis=1)\n",
    "\n",
    "data['zd_sk'] = data[['b20', 'zd_mid', 'b21']].apply(lambda x: skew(x), axis=1)\n",
    "data['zd_ku'] = data[['b20', 'zd_mid', 'b21']].apply(lambda x: kurtosis(x), axis=1)\n",
    "\n",
    "data['xf_sk'] = data[['b26', 'xf_mid', 'b27']].apply(lambda x: skew(x), axis=1)\n",
    "data['xf_ku'] = data[['b26', 'xf_mid', 'b27']].apply(lambda x: kurtosis(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d799c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除构造的可能造成冗余的特征\n",
    "data = data.drop([\"ed_mid\", \"zd_mid\", \"xf_mid\"], axis=1)\n",
    "data = data.drop([\"half_year_ed_sum\", \"3_month_ed_sum\", \"half_year_zd_sum\", \"3_month_zd_sum\", \"half_year_xf_sum\", \"3_month_xf_sum\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15df46b",
   "metadata": {},
   "source": [
    "## 特征分箱+异常值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeadfd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年龄 b1\n",
    "# 观察取值来分箱\n",
    "def get_b1_seg(x):\n",
    "    if x >=21 and x <= 22:\n",
    "        return 0 # 在以上取值区间内，返回0\n",
    "    elif x > 22 and x <= 24:\n",
    "        return 1 # 返回1\n",
    "    elif x > 24 and x <= 25:\n",
    "        return 2 # 返回2\n",
    "    elif x > 25 and x <= 26:\n",
    "        return 3 # 返回3\n",
    "    elif x > 26 and x <= 27:\n",
    "        return 4 # 返回4\n",
    "    elif x > 27 and x <= 28:\n",
    "        return 5 # 返回5\n",
    "data[\"b1_seg\"] = data[\"b1\"].apply(lambda x: get_b1_seg(x)) # 对年龄特征进行分箱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e94360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b26 近3个月最大消费金额\n",
    "def get_b26_seg(x):\n",
    "    if x <=0 : # 存在异常值\n",
    "        return 0\n",
    "    if x >=0 and x <= 8000:\n",
    "        return 1\n",
    "    if x >=8000 and x <= 40000:\n",
    "        return 2\n",
    "    elif x > 40000 and x <= np.max(data[\"b26\"]):\n",
    "        return 3\n",
    "data[\"b26_seg\"] = data[\"b26\"].apply(lambda x: get_b26_seg(x))\n",
    "data = data.drop([\"b26\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9980aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b10 近半年平均额度使用率\n",
    "def get_b10_seg(x):\n",
    "    if x >=0 and x <= 0.12:\n",
    "        return 0\n",
    "    if x >=0.12 and x <= 0.375:\n",
    "        return 1\n",
    "    if x >=0.375 and x <= 1:\n",
    "        return 2\n",
    "    if x >=1 and x <= np.max(data[\"b10\"]):\n",
    "        return 3\n",
    "data[\"b10_seg\"] = data[\"b10\"].apply(lambda x: get_b10_seg(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b11 近半年最大额度使用率\n",
    "def get_b11_seg(x):\n",
    "    if x >=0 and x <= 0.2:\n",
    "        return 0\n",
    "    if x >=0.2 and x <= 0.8:\n",
    "        return 1\n",
    "    if x >=0.8 and x <= 1.5:\n",
    "        return 2\n",
    "    if x >=1.5 and x <= np.max(data[\"b11\"]):\n",
    "        return 3\n",
    "data[\"b11_seg\"] = data[\"b11\"].apply(lambda x: get_b11_seg(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b150d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b23 近半年最大月消费金额\n",
    "def get_b23_seg(x):\n",
    "    if x >=0 and x <= 2000:\n",
    "        return 0\n",
    "    if x >=2000 and x <= 10000:\n",
    "        return 1\n",
    "    if x >=10000 and x <= 20000:\n",
    "        return 2\n",
    "    if x >=20000 and x <= np.max(data[\"b23\"]):\n",
    "        return 3\n",
    "data[\"b23_seg\"] = data[\"b23\"].apply(lambda x: get_b23_seg(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce2c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b21 近三个月最小账单金额\n",
    "def get_b21_seg(x):\n",
    "    if x <=0 : # 异常值\n",
    "        return 0\n",
    "    if x >=0 and x <= 10000:\n",
    "        return 1\n",
    "    if x >=10000 and x <= np.max(data[\"b21\"]):\n",
    "        return 2\n",
    "data[\"b21_seg\"] = data[\"b21\"].apply(lambda x: get_b21_seg(x))\n",
    "data = data.drop([\"b21\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6125937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b20 近三个月最大账单金额\n",
    "def get_b20_seg(x):\n",
    "    if x <=0 : # 异常值\n",
    "        return 0 \n",
    "    if x >=0 and x <= 10000:\n",
    "        return 1\n",
    "    if x >=10000 and x <= 20000:\n",
    "        return 2\n",
    "    if x >=20000 and x <= np.max(data[\"b20\"]):\n",
    "        return 3\n",
    "data[\"b20_seg\"] = data[\"b20\"].apply(lambda x: get_b20_seg(x))\n",
    "data = data.drop([\"b20\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff1972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b27 近三个月最小消费金额\n",
    "def get_b27_seg(x):\n",
    "    if x >=0 and x <= 5000:\n",
    "        return 0\n",
    "    if x >=5000 and x <= 10000:\n",
    "        return 1\n",
    "    if x >=10000 and x <= np.max(data[\"b27\"]): # 存在异常值\n",
    "        return 2\n",
    "data[\"b27_seg\"] = data[\"b27\"].apply(lambda x: get_b27_seg(x))\n",
    "data = data.drop([\"b27\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d06117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 异常值特征：b20 b21 b26 b27"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f45b716",
   "metadata": {},
   "source": [
    "## 时间特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#时间差值\n",
    "data['6-5'] = data['b6'] - data['b5'] # 激活时间与发卡时间的差值\n",
    "data['7-6'] = data['b7'] - data['b6'] # 首次交易时间与激活时间的差值\n",
    "data['7-5'] = data['b7'] - data['b5'] # 首次交易时间与发卡时间的差值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829140da",
   "metadata": {},
   "source": [
    "# 特征筛选"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4deb1",
   "metadata": {},
   "source": [
    "## 删除只有单一取值的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除单一取值的特征\n",
    "drop_cols= [\"id\", \"label\"]\n",
    "for f in data.columns:\n",
    "    if data[f].nunique() < 2: # nunique表示特征取不同值的数量 < 2表示只有单一取值\n",
    "        drop_cols.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a43a1ec",
   "metadata": {},
   "source": [
    "## 删除缺失率过高的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb55e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除缺失率过高的特征\n",
    "def dropNaN(df, p, col):\n",
    "    na_sum = df[col].isna().sum()\n",
    "    percent_value = na_sum / len(df[col])\n",
    "    if percent_value >= p:\n",
    "        df = df.drop([col], axis=1)\n",
    "    return df\n",
    "for c in data.columns:\n",
    "    data = dropNaN(data, 0.95, c) # 设置阈值为0.95，删除缺失率超出该阈值的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0800734",
   "metadata": {},
   "source": [
    "# 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be1bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据是否有标签划分训练集和测试集\n",
    "df_test = data[data[\"label\"].isnull() == True].copy().reset_index(drop=True)\n",
    "df_train = data[~data[\"label\"].isnull() == True].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a3b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = [f for f in df_train.columns if f not in drop_cols] # 所用的特征\n",
    "x_train = df_train[features_name].reset_index(drop=True)\n",
    "x_test = df_test[features_name].reset_index(drop=True)\n",
    "y = df_train[\"label\"].reset_index(drop=True)\n",
    "print(len(features_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e7a2e",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a6396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name, params):\n",
    "    \n",
    "    folds = 5\n",
    "    seed = 2023\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed) # 划分数据\n",
    "    \n",
    "    oof = np.zeros(train_x.shape[0]) # 初始化一个大小为n（n=训练集行数），值全为0的数组 用于存放每折验证集的预测概率\n",
    "    predict = np.zeros(test_x.shape[0]) # 初始化一个大小为n（n=测试集行数），值全为0的数组 用于存放预测概率\n",
    "\n",
    "    cv_scores = []\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} ************************************'.format(str(i+1)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "\n",
    "        if clf_name == \"lgb\":\n",
    "            train_matrix = clf.Dataset(trn_x, label=trn_y) # 该折训练集矩阵\n",
    "            valid_matrix = clf.Dataset(val_x, label=val_y) # 该折验证集矩阵\n",
    "    \n",
    "            # 模型训练 valid_sets也可以只放valid_matrix verbose_eval表示打印信息的间隔 early_stopping_rounds表示早停，\n",
    "            # 防止过拟合，表示在验证集上,当连续n次迭代,分数没有提高后,提前终止训练\n",
    "            model = clf.train(params, train_matrix, 100000, valid_sets=[train_matrix, valid_matrix], \n",
    "                              categorical_feature=[], verbose_eval=100, early_stopping_rounds=500) \n",
    "            val_pred = model.predict(val_x, num_iteration=model.best_iteration) # 预测该折验证集 最优迭代次数\n",
    "            test_pred = model.predict(test_x, num_iteration=model.best_iteration) # 该折训练下的模型来预测测试集\n",
    "            \n",
    "                 \n",
    "        if clf_name == \"cat\":\n",
    "            \n",
    "            model = clf(\n",
    "            n_estimators=10000,\n",
    "            random_seed=1024,\n",
    "            eval_metric='AUC',\n",
    "            learning_rate=0.05,\n",
    "            max_depth=5,\n",
    "            early_stopping_rounds=500,\n",
    "            metric_period=500,\n",
    "                    )\n",
    "\n",
    "            model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                      use_best_model=True,\n",
    "                      verbose=1)\n",
    "            \n",
    "            val_pred  = model.predict_proba(val_x)[:,1]\n",
    "            test_pred = model.predict_proba(test_x)[:,1]\n",
    "            \n",
    "        oof[valid_index] = val_pred # 将每一折验证集的预测结果放入原先的初始化矩阵中（每一折会对应索引valid_index）\n",
    "        \n",
    "        predict += test_pred / folds \n",
    "        \n",
    "        \n",
    "        cv_scores.append(roc_auc_score(val_y, val_pred))\n",
    "        print(cv_scores)\n",
    "    return oof, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb模型训练 第一套参数\n",
    "params1 = {\n",
    "    'learning_rate': 0.01, # 学习率\n",
    "    'boosting_type': 'gbdt', # 基学习器\n",
    "    'objective': 'binary',  # 采用的目标函数是binary，说明任务类型是二分类\n",
    "    'metric': 'auc', # 评估指标\n",
    "    'num_leaves': 63, # 叶子数\n",
    "    'feature_fraction': 0.8, # 在训练时，对某一棵树，随机选取的特征比例,调小该参数可以防止过拟合，加快运算速度\n",
    "    'bagging_fraction': 0.8, # 训练样本的采样比例,调小该参数可以防止过拟合，加快运算速度\n",
    "    'bagging_freq': 5, # 采样频率\n",
    "    'seed': 2022, # 随机数种子\n",
    "    'bagging_seed': 1, # bagging种子\n",
    "    'feature_fraction_seed': 7,\n",
    "    'min_data_in_leaf': 20, # 叶子节点上的最小数据样本量\n",
    "    'verbose': -1, \n",
    "    'n_jobs':8\n",
    "} \n",
    "start_time = datetime.now()\n",
    "lgb_oof1, lgb_pred1 = cv_model(lgb, x_train, y, x_test, 'lgb', params1)\n",
    "end_time = datetime.now()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80bd618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb模型训练 第二套参数\n",
    "params2 = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'metric': 'auc', \n",
    "    'min_child_weight': 5,\n",
    "    'num_leaves': 2 ** 5, \n",
    "    'lambda_l2': 10, # l2正则化\n",
    "    'feature_fraction': 0.8, \n",
    "    'bagging_fraction': 0.8, \n",
    "    'bagging_freq': 4, \n",
    "    'learning_rate': 0.01, \n",
    "    'seed': 2020,\n",
    "    'n_jobs':8,\n",
    "    'verbose': -1\n",
    "            }\n",
    "start_time = datetime.now()\n",
    "lgb_oof2, lgb_pred2 = cv_model(lgb, x_train, y, x_test, 'lgb', params2)\n",
    "end_time = datetime.now()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat模型训练\n",
    "start_time = datetime.now()\n",
    "cat_oof, cat_pred = cv_model(cat, x_train, y, x_test, 'cat', 5)\n",
    "end_time = datetime.now()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6091d32",
   "metadata": {},
   "source": [
    "# 模型加权融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a2e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_auc1 = roc_auc_score(df_train['label'], lgb_oof1)\n",
    "print(lgb_auc1)\n",
    "lgb_auc2 = roc_auc_score(df_train['label'], lgb_oof2)\n",
    "print(lgb_auc2)\n",
    "cat_auc = roc_auc_score(df_train['label'], cat_oof)\n",
    "print(cat_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e070d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_w1 = lgb_auc1 / (lgb_auc1 + lgb_auc2 + cat_auc)\n",
    "print(lgb_w1)\n",
    "lgb_w2 = lgb_auc2 / (lgb_auc1 + lgb_auc2 + cat_auc)\n",
    "print(lgb_w2)\n",
    "cat_w = cat_auc / (lgb_auc1 + lgb_auc2 + cat_auc)\n",
    "print(cat_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cebd958",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = lgb_w1 * lgb_oof1 + lgb_w2 * lgb_oof2 + cat_w * cat_oof\n",
    "pred = lgb_w1 * lgb_pred1 + lgb_w2 * lgb_pred2 + cat_w * cat_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a78bae",
   "metadata": {},
   "source": [
    "# 搜索最佳分类阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f5e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []; thresholds = []\n",
    "best_score = 0; best_threshold = 0\n",
    "\n",
    "for threshold in np.arange(0.05,0.8,0.001):\n",
    "    preds = (oof.reshape((-1))>threshold).astype('int')\n",
    "    f = f1_score(y.values.reshape((-1)), preds, average='macro') \n",
    "    scores.append(f)\n",
    "    thresholds.append(threshold)\n",
    "    \n",
    "    if f > best_score:\n",
    "        best_score = f\n",
    "        best_threshold = threshold\n",
    "    print(f'{threshold:.03f}, {f}')\n",
    "print(\"==============================\")\n",
    "print(f'{best_threshold:.03f}, {best_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ffeb6",
   "metadata": {},
   "source": [
    "# 模型线下得分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d04769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "auc_p = roc_auc_score(df_train['label'], oof)\n",
    "score = 0.3*auc_p+0.7*best_score\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8a5099",
   "metadata": {},
   "source": [
    "# 生成提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0629736",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pre=[1 if x >= 0.195 else 0 for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame()\n",
    "submit['id'] = df_test['id']\n",
    "submit['pred_prob'] = pred\n",
    "submit['pred_label'] = label_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac28affc",
   "metadata": {},
   "source": [
    "# 可解释性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402990a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2853d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(lgb_model2)\n",
    "shap_values = explainer.shap_values(x_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "shap.summary_plot(shap_values[1], x_test, show=False, plot_size=(8, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829cfa65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d58d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
